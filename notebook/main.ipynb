{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProgressiveGenerator, ProgressiveDiscriminator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     discriminator_loss, generator_loss, cycle_consistency_loss, identity_loss\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from lib.models import ProgressiveGenerator, ProgressiveDiscriminator\n",
    "from lib.losses import (\n",
    "    discriminator_loss, generator_loss, cycle_consistency_loss, identity_loss\n",
    ")\n",
    "from lib.data_loader import get_dataloader\n",
    "import matplotlib.pyplot as plt  # Import matplotlib\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('checkpoints', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "G_XtoY = ProgressiveGenerator().to(device)\n",
    "G_YtoX = ProgressiveGenerator().to(device)\n",
    "D_X = ProgressiveDiscriminator().to(device)\n",
    "D_Y = ProgressiveDiscriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "g_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters())\n",
    "d_params = list(D_X.parameters()) + list(D_Y.parameters())\n",
    "g_optimizer = Adam(g_params, lr=2e-4, betas=(0.5, 0.999))\n",
    "d_optimizer = Adam(d_params, lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "# Training settings\n",
    "epochs_per_scale = 5\n",
    "start_scale = G_XtoY.start_scale\n",
    "max_scale = G_XtoY.max_scale\n",
    "lambda_cycle = 10.0\n",
    "lambda_identity = 5.0\n",
    "initial_lr = 2e-4\n",
    "\n",
    "# Training loop\n",
    "scale = start_scale\n",
    "while scale <= max_scale:\n",
    "    print(f\"Training at scale: {scale}x{scale}\")\n",
    "    # Data loaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((scale, scale)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Adjust for RGB images if needed\n",
    "    ])\n",
    "    dataloader_X = get_dataloader('cifar10', './data', transform, batch_size=1)\n",
    "    dataloader_Y = get_dataloader('monet', './data/monet', transform, batch_size=1)\n",
    "    dataloader = zip(dataloader_X, dataloader_Y)\n",
    "\n",
    "    for epoch in range(1, epochs_per_scale + 1):\n",
    "        # For collecting examples\n",
    "        example_originals = []\n",
    "        example_generated = []\n",
    "\n",
    "        for i, (real_X, real_Y) in enumerate(tqdm(dataloader, total=min(len(dataloader_X), len(dataloader_Y)))):\n",
    "            real_X = real_X.to(device)\n",
    "            real_Y = real_Y.to(device)\n",
    "            # ------------------\n",
    "            #  Train Generators\n",
    "            # ------------------\n",
    "            g_optimizer.zero_grad()\n",
    "            # Identity loss\n",
    "            same_X = G_YtoX(real_X)\n",
    "            loss_identity_X = identity_loss(real_X, same_X, lambda_identity)\n",
    "            same_Y = G_XtoY(real_Y)\n",
    "            loss_identity_Y = identity_loss(real_Y, same_Y, lambda_identity)\n",
    "            # GAN loss\n",
    "            fake_Y = G_XtoY(real_X)\n",
    "            pred_fake = D_Y(fake_Y)\n",
    "            loss_GAN_XtoY = generator_loss(pred_fake)\n",
    "            fake_X = G_YtoX(real_Y)\n",
    "            pred_fake = D_X(fake_X)\n",
    "            loss_GAN_YtoX = generator_loss(pred_fake)\n",
    "            # Cycle consistency loss\n",
    "            recov_X = G_YtoX(fake_Y)\n",
    "            loss_cycle_X = cycle_consistency_loss(real_X, recov_X, lambda_cycle)\n",
    "            recov_Y = G_XtoY(fake_X)\n",
    "            loss_cycle_Y = cycle_consistency_loss(real_Y, recov_Y, lambda_cycle)\n",
    "            # Total loss\n",
    "            loss_G = (\n",
    "                loss_identity_X + loss_identity_Y +\n",
    "                loss_GAN_XtoY + loss_GAN_YtoX +\n",
    "                loss_cycle_X + loss_cycle_Y\n",
    "            )\n",
    "            loss_G.backward()\n",
    "            g_optimizer.step()\n",
    "            # -----------------------\n",
    "            #  Train Discriminators\n",
    "            # -----------------------\n",
    "            d_optimizer.zero_grad()\n",
    "            # Discriminator X\n",
    "            pred_real = D_X(real_X)\n",
    "            pred_fake = D_X(fake_X.detach())\n",
    "            loss_D_X = discriminator_loss(pred_real, pred_fake)\n",
    "            loss_D_X.backward()\n",
    "            # Discriminator Y\n",
    "            pred_real = D_Y(real_Y)\n",
    "            pred_fake = D_Y(fake_Y.detach())\n",
    "            loss_D_Y = discriminator_loss(pred_real, pred_fake)\n",
    "            loss_D_Y.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Collect examples\n",
    "            if i < 3:\n",
    "                # Detach to prevent memory leaks\n",
    "                example_originals.append(real_X.cpu())\n",
    "                example_generated.append(fake_Y.cpu())\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs_per_scale}] Loss_G: {loss_G.item():.4f} Loss_D_X: {loss_D_X.item():.4f} Loss_D_Y: {loss_D_Y.item():.4f}\")\n",
    "        # Display sample images\n",
    "        originals = torch.cat(example_originals, 0)\n",
    "        generated = torch.cat(example_generated, 0)\n",
    "\n",
    "        # Denormalize images for visualization\n",
    "        def denormalize(tensors):\n",
    "            return tensors * 0.5 + 0.5\n",
    "\n",
    "        # Convert tensors to numpy arrays\n",
    "        originals = denormalize(originals).numpy().transpose(0, 2, 3, 1)\n",
    "        generated = denormalize(generated).numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        # Plot images\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 15))\n",
    "        for idx in range(3):\n",
    "            axes[idx, 0].imshow(np.clip(originals[idx], 0, 1))\n",
    "            axes[idx, 0].axis('off')\n",
    "            axes[idx, 0].set_title('Original Image')\n",
    "            axes[idx, 1].imshow(np.clip(generated[idx], 0, 1))\n",
    "            axes[idx, 1].axis('off')\n",
    "            axes[idx, 1].set_title('Generated Image')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Increase scale\n",
    "    G_XtoY.increase_scale()\n",
    "    G_YtoX.increase_scale()\n",
    "    D_X.increase_scale()\n",
    "    D_Y.increase_scale()\n",
    "    # Adjust learning rates if needed\n",
    "    scale *= 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
